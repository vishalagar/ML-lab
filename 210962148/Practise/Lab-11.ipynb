{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for the new sample: Yes\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "data = pd.read_csv(\"data_dt.csv\")\n",
    "data = data.drop(\"Day\", axis=1)\n",
    "\n",
    "def entropy(target_column):\n",
    "    elements, counts = np.unique(target_column, return_counts=True)\n",
    "    entropy = 0\n",
    "    for count in counts:\n",
    "        probability = count / len(target_column)\n",
    "        entropy -= probability * math.log2(probability)\n",
    "    return entropy\n",
    "\n",
    "def information_gain(data, feature, target):\n",
    "    total_entropy = entropy(data[target])\n",
    "    values, counts = np.unique(data[feature], return_counts=True)\n",
    "    weighted_entropy = 0\n",
    "    for value, count in zip(values, counts):\n",
    "        subset = data[data[feature] == value]\n",
    "        subset_entropy = entropy(subset[target])\n",
    "        weighted_entropy += (count / len(data)) * subset_entropy\n",
    "    return total_entropy - weighted_entropy\n",
    "\n",
    "def best_split(data, features, target):\n",
    "    information_gains = []\n",
    "    for feature in features:\n",
    "        information_gains.append(information_gain(data, feature, target))\n",
    "    return features[np.argmax(information_gains)]\n",
    "\n",
    "def id3(data, original_data, features, target_attribute_name, parent_node_class=None):\n",
    "    # If all target values are the same, return this value\n",
    "    if len(np.unique(data[target_attribute_name])) <= 1:\n",
    "        return np.unique(data[target_attribute_name])[0]\n",
    "\n",
    "    # If dataset is empty, return the mode target feature value in the original dataset\n",
    "    elif len(data) == 0:\n",
    "        return np.unique(original_data[target_attribute_name])[np.argmax(np.unique(original_data[target_attribute_name], return_counts=True)[1])]\n",
    "\n",
    "    # If there are no features left to split the data, return the mode target feature value of the current node\n",
    "    elif len(features) == 0:\n",
    "        return parent_node_class\n",
    "\n",
    "    # Otherwise, grow the tree\n",
    "    else:\n",
    "        parent_node_class = np.unique(data[target_attribute_name])[np.argmax(np.unique(data[target_attribute_name], return_counts=True)[1])]\n",
    "\n",
    "        best_feature = best_split(data, features, target_attribute_name)\n",
    "        tree = {best_feature: {}}\n",
    "\n",
    "        features = [i for i in features if i != best_feature]\n",
    "\n",
    "        for value in np.unique(data[best_feature]):\n",
    "            value = value\n",
    "            sub_data = data.where(data[best_feature] == value).dropna()\n",
    "            subtree = id3(sub_data, data, features, target_attribute_name, parent_node_class)\n",
    "            tree[best_feature][value] = subtree\n",
    "\n",
    "        return tree\n",
    "\n",
    "def classify(sample, tree, default=None):\n",
    "    attribute = next(iter(tree))\n",
    "\n",
    "    if sample[attribute] in tree[attribute].keys():\n",
    "        result = tree[attribute][sample[attribute]]\n",
    "        if isinstance(result, dict):\n",
    "            return classify(sample, result)\n",
    "        else:\n",
    "            return result\n",
    "    else:\n",
    "        return default\n",
    "\n",
    "# Build the decision tree\n",
    "target_attribute_name = \"Decision\"\n",
    "features = data.columns.difference([target_attribute_name])\n",
    "tree = id3(data, data, features, target_attribute_name)\n",
    "\n",
    "# Classify a new sample\n",
    "new_sample = {\"Outlook\": \"Sunny\", \"Temperature\": \"Low\", \"Humidity\": \"Medium\", \"Wind\": \"Weak\"}\n",
    "result = classify(new_sample, tree, \"No\")\n",
    "\n",
    "print(f\"Prediction for the new sample: {result}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for the new sample: Yes\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "data = pd.read_csv(\"data_dt.csv\")\n",
    "data = data.drop(\"Day\", axis=1)\n",
    "\n",
    "def entropy(target_column):\n",
    "    elements, counts = np.unique(target_column, return_counts=True)\n",
    "    entropy = 0\n",
    "    for count in counts:\n",
    "        probability = count / len(target_column)\n",
    "        entropy -= probability * math.log2(probability)\n",
    "    return entropy\n",
    "\n",
    "def information_gain(data, feature, target):\n",
    "    total_entropy = entropy(data[target])\n",
    "    values, counts = np.unique(data[feature], return_counts=True)\n",
    "    weighted_entropy = 0\n",
    "    for value, count in zip(values, counts):\n",
    "        subset = data[data[feature] == value]\n",
    "        subset_entropy = entropy(subset[target])\n",
    "        weighted_entropy += (count / len(data)) * subset_entropy\n",
    "    return total_entropy - weighted_entropy\n",
    "\n",
    "def gain_ratio(data, feature, target):\n",
    "    info_gain = information_gain(data, feature, target)\n",
    "    values, counts = np.unique(data[feature], return_counts=True)\n",
    "    split_info = 0\n",
    "    for count in counts:\n",
    "        probability = count / len(data)\n",
    "        split_info -= probability * math.log2(probability)\n",
    "    return info_gain / split_info\n",
    "\n",
    "def best_split(data, features, target):\n",
    "    gain_ratios = []\n",
    "    for feature in features:\n",
    "        gain_ratios.append(gain_ratio(data, feature, target))\n",
    "    return features[np.argmax(gain_ratios)]\n",
    "\n",
    "def c45(data, original_data, features, target_attribute_name, parent_node_class=None):\n",
    "    # If all target values are the same, return this value\n",
    "    if len(np.unique(data[target_attribute_name])) <= 1:\n",
    "        return np.unique(data[target_attribute_name])[0]\n",
    "\n",
    "    # If dataset is empty, return the mode target feature value in the original dataset\n",
    "    elif len(data) == 0:\n",
    "        return np.unique(original_data[target_attribute_name])[np.argmax(np.unique(original_data[target_attribute_name], return_counts=True)[1])]\n",
    "\n",
    "    # If there are no features left to split the data, return the mode target feature value of the current node\n",
    "    elif len(features) == 0:\n",
    "        return parent_node_class\n",
    "\n",
    "    # Otherwise, grow the tree\n",
    "    parent_node_class = np.unique(data[target_attribute_name])[np.argmax(np.unique(data[target_attribute_name], return_counts=True)[1])]\n",
    "\n",
    "    best_feature = best_split(data, features, target_attribute_name)\n",
    "    tree = {best_feature: {}}\n",
    "\n",
    "    features = [i for i in features if i != best_feature]\n",
    "\n",
    "    for value in np.unique(data[best_feature]):\n",
    "        value = value\n",
    "        sub_data = data.where(data[best_feature] == value).dropna()\n",
    "        subtree = c45(sub_data, data, features, target_attribute_name, parent_node_class)\n",
    "        tree[best_feature][value] = subtree\n",
    "\n",
    "    return tree\n",
    "\n",
    "# Function to classify a new sample\n",
    "def classify(sample, tree, default=None):\n",
    "    attribute = next(iter(tree))\n",
    "\n",
    "    if sample[attribute] in tree[attribute].keys():\n",
    "        result = tree[attribute][sample[attribute]]\n",
    "        if isinstance(result, dict):\n",
    "            return classify(sample, result)\n",
    "        else:\n",
    "            return result\n",
    "    else:\n",
    "        return default\n",
    "\n",
    "# Build the C4.5 decision tree\n",
    "target_attribute_name = \"Decision\"\n",
    "features = data.columns.difference([target_attribute_name])\n",
    "tree = c45(data, data, features, target_attribute_name)\n",
    "\n",
    "# Classify a new sample\n",
    "new_sample = {\"Outlook\": \"Sunny\", \"Temperature\": \"High\", \"Humidity\": \"Medium\", \"Wind\": \"Weak\"}\n",
    "result = classify(new_sample, tree, \"No\")\n",
    "\n",
    "print(f\"Prediction for the new sample: {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for the sample (75, 80): Yes\n",
      "Prediction for the sample (70, 70): No\n",
      "Prediction for the sample (83, 78): Yes\n",
      "Prediction for the sample (68, 80): Yes\n",
      "Prediction for the sample (81, 75): Yes\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Define the dataset\n",
    "data = pd.read_csv(\"data_dt_CART.csv\")\n",
    "\n",
    "# Define the DecisionTree class\n",
    "class DecisionTree:\n",
    "    def __init__(self, max_depth=None):\n",
    "        self.max_depth = max_depth\n",
    "        self.tree = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.tree = self._build_tree(X, y, depth=0)\n",
    "\n",
    "    def _build_tree(self, X, y, depth):\n",
    "        if depth == self.max_depth or len(np.unique(y)) == 1:\n",
    "            return np.argmax(np.bincount(y))\n",
    "\n",
    "        num_samples, num_features = X.shape\n",
    "        best_gini = 1.0\n",
    "        best_feature = None\n",
    "        best_split = None\n",
    "\n",
    "        for feature in range(num_features):\n",
    "            unique_values = np.unique(X[:, feature])\n",
    "            for value in unique_values:\n",
    "                left_indices = np.where(X[:, feature] <= value)[0]\n",
    "                right_indices = np.where(X[:, feature] > value)[0]\n",
    "\n",
    "                left_gini = self._calculate_gini(y[left_indices])\n",
    "                right_gini = self._calculate_gini(y[right_indices])\n",
    "                gini = (len(left_indices) / num_samples) * left_gini + (len(right_indices) / num_samples) * right_gini\n",
    "\n",
    "                if gini < best_gini:\n",
    "                    best_gini = gini\n",
    "                    best_feature = feature\n",
    "                    best_split = value\n",
    "\n",
    "        if best_gini == 1.0:\n",
    "            return np.argmax(np.bincount(y))\n",
    "\n",
    "        left_indices = np.where(X[:, best_feature] <= best_split)[0]\n",
    "        right_indices = np.where(X[:, best_feature] > best_split)[0]\n",
    "\n",
    "        left_tree = self._build_tree(X[left_indices], y[left_indices], depth + 1)\n",
    "        right_tree = self._build_tree(X[right_indices], y[right_indices], depth + 1)\n",
    "\n",
    "        return (best_feature, best_split, left_tree, right_tree)\n",
    "\n",
    "    def _calculate_gini(self, y):\n",
    "        if len(y) == 0:\n",
    "            return 0\n",
    "        p0 = np.sum(y == 0) / len(y)\n",
    "        p1 = np.sum(y == 1) / len(y)\n",
    "        return 1 - p0**2 - p1**2\n",
    "\n",
    "    def predict(self, X):\n",
    "        predictions = []\n",
    "        for x in X:\n",
    "            node = self.tree\n",
    "            while isinstance(node, tuple):\n",
    "                feature, split, left, right = node\n",
    "                if x[feature] <= split:\n",
    "                    node = left\n",
    "                else:\n",
    "                    node = right\n",
    "            predictions.append(node)\n",
    "        return np.array(predictions)\n",
    "\n",
    "# Prepare data using only \"Temperature\" and \"Humidity\"\n",
    "X = data[[\"Temperature\", \"Humidity\"]].values\n",
    "y = (data[\"Decision\"] == \"Yes\").astype(int).values\n",
    "\n",
    "# Build the CART decision tree\n",
    "tree = DecisionTree(max_depth=4)\n",
    "tree.fit(X, y)\n",
    "\n",
    "'''# Sample for which the prediction should be \"Yes\"\n",
    "new_sample = np.array([75, 80])  # Temperature: 75, Humidity: 80\n",
    "new_sample = np.reshape(new_sample, (1, -1))\n",
    "prediction = tree.predict(new_sample)\n",
    "\n",
    "if prediction[0] == 1:\n",
    "    result = \"Yes\"\n",
    "else:\n",
    "    result = \"No\"\n",
    "\n",
    "print(f\"Prediction for the new sample: {result}\")'''\n",
    "\n",
    "samples = [\n",
    "    (75, 80),  # Temperature: 75, Humidity: 80\n",
    "    (70, 70),  # Temperature: 70, Humidity: 70\n",
    "    (83, 78),  # Temperature: 83, Humidity: 78\n",
    "    (68, 80),  # Temperature: 68, Humidity: 80\n",
    "    (81, 75),  # Temperature: 81, Humidity: 75\n",
    "]\n",
    "\n",
    "for sample in samples:\n",
    "    prediction = tree.predict(np.array(sample).reshape(1, -1))\n",
    "    if prediction[0] == 1:\n",
    "        result = \"Yes\"\n",
    "    else:\n",
    "        result = \"No\"\n",
    "    print(f\"Prediction for the sample {sample}: {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
